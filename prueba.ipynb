{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dwadadadadadadawdada.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"merging_merge_on_key.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot_6.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA DATAFRAME PASO A PASO\n",
    "df = pd.read_csv(\" \", encoding='utf-8')\n",
    "df.info()\n",
    "#Reviso si hay nulos\n",
    "for col in df:\n",
    "    nulos = df[col].isna().sum()\n",
    "    print('-------------------')\n",
    "    print(f'La columna {col} posee {nulos} nulos')\n",
    "#SACO LOS NULOS\n",
    "dfclean = df.dropna(inplace=True)\n",
    "dfclean.info()\n",
    "#REVISO DUPLICADOS\n",
    "dfclean[dfclean.duplicated()]\n",
    "#SI HAY OCUPO ESTO\n",
    "dfclean = dfclean.drop_duplicates(keep=\"first\")\n",
    "dfclean.info()\n",
    "#Reviso los datos por si hay que hacer algun cambio\n",
    "dfclean.describe()\n",
    "#SI ME PIDEN SACAR ALGUNAS COLUMNAS\n",
    "df.drop([' ', ' ', ' '], axis='columns', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING ALGORITMO\n",
    "dummies = pd.get_dummies(df[' ']).map(lambda x: int(x))\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGREGAR EL ENCODING AL DATAFRAME\n",
    "dummies = pd.get_dummies(df[' ']).map(lambda x: int(x))\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "df.drop([' '],axis='columns', inplace=True) #Rellenar con columna\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTRENAR MODELO DE APRENDIZAJE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "df = pd.read_csv(\" \", encoding='utf-8')\n",
    "\n",
    "#Ver el dataframe\n",
    "df.head()\n",
    "\n",
    "#Revisar el Dtype de los datos\n",
    "df.dtypes\n",
    "\n",
    "#Ver la info completa\n",
    "df.info()\n",
    "\n",
    "#Revisar las columnas\n",
    "df.columns\n",
    "\n",
    "#Copia\n",
    "df2 = df.copy()\n",
    "\n",
    "#Revisar filas sirve para revisar datos rapidamente y analizar la estrucutura del dataset\n",
    "df.tail()\n",
    "\n",
    "#Sumar\n",
    "df[\" \"].sum()\n",
    "\n",
    "#Ver cuando valores unicos existen\n",
    "df.unique()\n",
    "\n",
    "#Para ver los valores unicos de una columna \n",
    "df.xxx.unique()\n",
    "\n",
    "#Si hay duplicados de variables mayusculas y minusculas ocupar\n",
    "df[' '] = df[' '].map(lambda x: str(x).lower())\n",
    "df.unique()\n",
    "\n",
    "#Describe sirve para ver todo lo que sea mediana percentiles etc. todo esto para calculo de estadisticas\n",
    "df.describe()\n",
    "\n",
    "#Tambien si quiero saber con diferentes columnas\n",
    "df[[' ',' ']].describe()\n",
    "\n",
    "#Sumar datos distintas columnas\n",
    "df[' '].sum()+df[' '].sum()+df[' '].sum()\n",
    "\n",
    "#Cambiar a distintos tipos de dtype\n",
    "df[\" \"] = df[\" \"].astype(\"category\")\n",
    "df[\" \"] = df[\" \"].astype(\"float\")\n",
    "df[\" \"] = df[\" \"].astype(\"int\")\n",
    "df[\" \"] = df[\" \"].astype(\"datetime64[ns]\")\n",
    "\n",
    "#Revisar la columna de un df cuando no se puede ocupar .describe() es cuando hay texto asi que tiene que ser columna numerica\n",
    "df[\" \"].describe()\n",
    "\n",
    "#Si se encuentra una columna con texto y numeros ocupamos \"category\"\n",
    "df[\" \"] = df[\" \"].astype(\"category\")\n",
    "\n",
    "#Sacar los duplicados del df y dejar uno\n",
    "df = df.drop_duplicates(keep=\"first\")\n",
    "\n",
    "#Revisar si hay duplicados\n",
    "df[df.duplicated()]\n",
    "\n",
    "#Dropear todos los NaN de un df completo\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Limpiar datos nuevo y crear un nuevo df limpio\n",
    "df_clean = df.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego NaN a las columnas con los datos vacios\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "#Borro las columnas con NaN\n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comandos numpy para calcular estadisticas\n",
    "np.mean() #es la suma de todos los valores, dividida por el número de puntos.\n",
    "np.median() #es el valor medio de un conjunto de datos, elige el valor que queda en la mitad.\n",
    "np.percentile() #percentil\n",
    "np.var() #promedio de la distancia cuadrática, medida de la dispersión de los datos\n",
    "np.std() #es la raíz cuadrada de la varianza\n",
    "np.cov() #es una medida de cómo dos cantidades varían juntas\n",
    "np.corrcoef #para tener una medida más general y aplicable de la correlación entre dos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos Duplicados revisar\n",
    "duplicates = df.duplicated(keep=False)\n",
    "dups = df[duplicates].sort_values(by=\" \") #Ahi va lo que quieres revisar si hay duplicados\n",
    "dups\n",
    "#Sacar los duplicados del df y dejar uno\n",
    "df = df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos nulos de todo el DF\n",
    "#Revisar en que columnas hay valores nulos\n",
    "for col in xx:\n",
    "    nulos = xx[col].isna().sum()\n",
    "    print('-------------------')\n",
    "    print(f'La columna {col} posee {nulos} nulos')\n",
    "\n",
    "#Identificar los datos faltantes\n",
    "df.isna()\n",
    "\n",
    "#Si en un dataframe hay diferentes tipos de valores nulos podemos ponerles NaN con este comando #ESTO ES UN EJEMPLO REEMPLAZA LAS \" \" con los datos del dataframe Nulos\n",
    "df = df.replace('*', np.nan)\n",
    "df = df.replace('None', np.nan)\n",
    "df = df.replace(' ', np.nan)\n",
    "df = df.replace(-999, np.nan)\n",
    "\n",
    "#Dropear todos los NaN de un df completo\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Dropear una columna\n",
    "df = df.drop()\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#Revisar en que columnas hay valores nulos\n",
    "for col in xx:\n",
    "    nulos = xx[col].isna().sum()\n",
    "    print('-------------------')\n",
    "    print(f'La columna {col} posee {nulos} nulos')\n",
    "\n",
    "#Datos nulos en columnas\n",
    "nan_df = df[\" \"].isna()\n",
    "\n",
    "#Revisar si hay nulos en la columna seleccionada\n",
    "nan_df\n",
    "\n",
    "#Sacar los datos nulos de la columna pero modificando el DataFrame original\n",
    "df.dropna(subset = [\" \"], inplace=True)\n",
    "\n",
    "#Sacar los datos nulos de la columna al hacer esto dps hay que hacer una copia \n",
    "df.dropna(subset=[\" \"])\n",
    "\n",
    "#Podemos agregar un valor a un Nan con este comando si es necesario\n",
    "df2[\" \"] = df2[\" \"].fillna(value= \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                             \n",
    "#Calcular sum,mean,std,count de las columnas\n",
    "df = pd.pivot_table(df, index=\" \", values= \" \", aggfunc=[\"sum\",\"mean\",\"std\",\"count\"]) # Index es la columna que queremos ocupar, values es para agregar otra columna por si queremos ocuparla\n",
    "                                                                                      # tambien y aggfunc es para agregar las operaciones que les asignamos a una nueva tabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si queremos manejar solo un conjunto de datos hacemos esto\n",
    "conjunto = \" \" #Aca va la columna\n",
    "data_select = df[df[\" \"]==conjunto] #Aca va el datasetcreado antes \"datasets = df.dataset.unique()\" para poder trabajar en las columnas\n",
    "\n",
    "#Calcular 1 solo tipo de datos\n",
    "data_select[[\"x\", \"y\"]].mean() #mean,median,var,std,quantile(0.25) en la x e y van las columnas STD ES DESVIACION ESTANDAR\n",
    "\n",
    "#Calcular correlacion o covarianza de columnas \n",
    "corr = data_select['x'].corr(data_select['y']) o corr = data_select['y'].corr(data_select['x'])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concadenar dataframes\n",
    "nuevo_dataframe = primer_dataframe.merge(segundo_dataframe, how='left', left_on=\" \", right_on=\" \") #Left usa solo las keys del izquierdo df y left_on es para agarrar una columna para unirla a la\n",
    "                                                                                                   #otra el \" \" se rellena con la columna y el right_on usa solo las keys del derecho para dejarla\n",
    "                                                                                                   #en una sola FOTO ARRIBA\n",
    "\n",
    "nuevo_dataframe = primer_dataframe.merge(segundo_dataframe[[' ', ' ', ' ', ' ']], how='left', left_on=' ', right_on=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAR HEATMAP CON CORRELACION\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True)\n",
    "#GRAFICO DE PARES CON SCATTER PLOT\n",
    "sns.pairplot(df)\n",
    "#GRAFICO CON VARIABLES INDEPENDIENTES E DEPENDIENTES\n",
    "sns.pairplot(data=df, y_vars=' dependiente', x_vars=' independiente', hue='color ', height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comandos seaborn GRAFICAR\n",
    "datasns = sns.load_dataset(\" \")#Aca va el archivo\n",
    "datasns.info() #Para saber las columnas y el nombre a utilizar\n",
    "\n",
    "#HISTOGRAMAS PUNTOS\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9,3))\n",
    "ax = sns.scatterplot(data.XX) #Reemplazar el XX con la columna a utlizar\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "#HISTOGRAMAS BARRAS\n",
    "sns.displot(data.XX, kde=False, bins=20) #Reemplazar el XX con la columna a utlizar\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "\n",
    "#Mapa de calor\n",
    "sns.heatmap(corr)\n",
    "\n",
    "#Explorar datos con graficos\n",
    "sns.pairplot(df, y_vars=' ') #Agregar columna\n",
    "sns.pairplot(df, hue=' ') #Agregar columna\n",
    "\n",
    "#Explorar correlacion en un heatmap\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True)\n",
    "\n",
    "#Explorar promedio entre dos variables\n",
    "sns.pairplot(data=df, y_vars=' ', x_vars=' ', hue=' ', height=8) #Agregar columna\n",
    "\n",
    "#Grafico de puntos con linea de regresion de diferentes variables\n",
    "sns.lmplot(data=df, y=' ', x=' ', hue=' ', height=8) #Agregar columnas hue es para la columna que quieres que se rijan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjuntos de entrenamiento StandarScaler ejemplo\n",
    "y_magnitude = earthquakes['magnitude']\n",
    "y_tsunami = earthquakes['tsunami']\n",
    "\n",
    "X_magnitude = earthquakes.drop(['magnitude'],axis='columns')\n",
    "X_tsunami = earthquakes.drop(['tsunami'],axis='columns')\n",
    "\n",
    "#Regresion lineal\n",
    "# Dividir en conjunto de prueba y entrenamiento (Usar test size 2 y random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_magnitude, y_magnitude,test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cienciadedatos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
